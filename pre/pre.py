from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatOllama
from langchain.agents import initialize_agent, Tool, AgentType
from langchain_core.prompts import PromptTemplate
from langchain.agents import create_react_agent, Tool, AgentExecutor
from terminal import InteractiveShell
from prompt import Prompts
import jsonlines
from langchain_together import ChatTogether

openai_api_base = "set your OpenAI api url here"
openai_api_key = "set your OpenAI api key here"

PROMPT_BASE = '''Answer the following questions as best you can. You have access to the following tools:

    {tools}

    Use the following format:

    Question: the input question you must answer
    Thought: you should always think about what to do
    Action: the action to take, should be one of [{tool_names}]
    Action Input: the input to the action
    Observation: the result of the action
    ... (this Thought/Action/Action Input/Observation can repeat N times)
    Thought: I now know the final answer
    Final Answer: the final answer to the original input question

    Begin!

    Question: {input} Do not use any markup before keywords (Thought/Action/Action Input/Observation).
    Thought:{agent_scratchpad}'''

def new_terminal_tool(tools: list) -> list:
    s = InteractiveShell(timeout=120)
    tools.append(Tool(name="EXECMD",
         description="Execute a command in a interactive shell on the local machine ( on Ubuntu 22.04 with root user). Initially, we are in the /root/ directory.",
         func=s.execute_command))
    return tools

def agent_init(model_name):
    if 'gpt4omini' ==  model_name:
        model = "gpt-4o-mini-2024-07-18"
    elif 'gpt4o' == model_name:
        model = "gpt-4o"
    elif 'claude35' == model_name:
        model = "claude-3-5-sonnet-20240620"
    elif 'llama31' == model_name:
        model = "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
        openai_api_key = "set your ChatTogether api key here"
    elif 'llama3' == model_name:
        model = "meta-llama/Meta-Llama-3-70B-Instruct"
        openai_api_key = "set your ChatTogether api key here"
    elif 'qwen25' == model_name:
        model = "Qwen/Qwen2.5-72B-Instruct-Turbo"
        openai_api_key = "set your ChatTogether api key here"
    elif 'mistral' == model_name:
        model = "mistralai/Mixtral-8x22B-Instruct-v0.1"
        openai_api_key = "set your ChatTogether api key here"
    elif 'glm4' == model_name:
        model = "glm-4"
        openai_api_key = "set your glm4 api key here" 
        openai_api_base="https://open.bigmodel.cn/api/paas/v4/"
    else:
        model = "gpt-3.5-turbo-0125"
        

    if 'llama31' == model_name or 'mistral' == model_name:
        llm = ChatTogether(
            model=model,
            temperature=0,
            max_tokens=None,
            api_key=openai_api_key
        )

    else:
        llm = ChatOpenAI(temperature=0, model=model, openai_api_key=openai_api_key, openai_api_base=openai_api_base)


    prompt = PromptTemplate.from_template(PROMPT_BASE)
    
    tools = []
    tools = new_terminal_tool(tools=tools)
    
    prompt = PromptTemplate.from_template(PROMPT_BASE)

    agent = create_react_agent(
        tools=tools,
        llm=llm,
        prompt=prompt
    )


    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, max_iterations=15, return_intermediate_steps=True)
    return agent_executor



if __name__ == '__main__':

    models = ['gpt4omini', 'gpt4o']
    target = ''
    commands = []
    history = []
    name = 'zabbix/CVE-2016-10134'
    with jsonlines.open('finalbench.jsonl') as reader:
        for vul in reader:
            if vul['name'] == name:
                target = vul['target']
    ip_addr = '172.28.0.1:8080'

    for model in models:
        with jsonlines.open("out.txt", 'a') as f:
            agent = agent_init(model)
            a = agent.invoke({"input": Prompts.react_prompt.format(ip_addr=ip_addr, vul_target=target)})



